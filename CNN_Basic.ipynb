{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Original Code from Saraj Ai </h1>\n",
       "<a>https://www.youtube.com/watch?v=FTr3n7uBIuE&index=8&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D</a>\n",
       "<h2>github:<a><h5>https://www.youtube.com/redirect?v=FTr3n7uBIuE&event=video_description&redir_token=Vh1Z2mNefWEXxy5oFF9FJak7A9h8MTU0OTAyODQyN0AxNTQ4OTQyMDI3&q=https%3A%2F%2Fgithub.com%2FllSourcell%2FConvolutional_neural_network</h5></a></h2>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html \n",
    "<h1>Original Code from Saraj Ai </h1>\n",
    "<a>https://www.youtube.com/watch?v=FTr3n7uBIuE&index=8&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D</a>\n",
    "<h2>github:<a><h5>https://www.youtube.com/redirect?v=FTr3n7uBIuE&event=video_description&redir_token=Vh1Z2mNefWEXxy5oFF9FJak7A9h8MTU0OTAyODQyN0AxNTQ4OTQyMDI3&q=https%3A%2F%2Fgithub.com%2FllSourcell%2FConvolutional_neural_network</h5></a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>\n",
       "    Process CNN \n",
       "    <h5>\n",
       "        <ul>\n",
       "            <li>Prepare dataset</li>\n",
       "            <li>Convolution</li>\n",
       "            <li>Relu activation</li>\n",
       "            <li>Pooling</li>\n",
       "            <li>Dropout</li>\n",
       "            <li>Flatten</li>\n",
       "            <li>Dense</li>\n",
       "            <li>Softmax</li>\n",
       "        </ul>\n",
       "    </h5>\n",
       "\n",
       "</h3>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h3>\n",
    "    Process CNN \n",
    "    <h5>\n",
    "        <ul>\n",
    "            <li>Prepare dataset</li>\n",
    "            <li>Convolution</li>\n",
    "            <li>Relu activation</li>\n",
    "            <li>Pooling</li>\n",
    "            <li>Dropout</li>\n",
    "            <li>Flatten</li>\n",
    "            <li>Dense</li>\n",
    "            <li>Softmax</li>\n",
    "        </ul>\n",
    "    </h5>\n",
    "\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.layer = []\n",
    "        self.pool_size = None\n",
    "        \n",
    "    def load_weights(self, weights):\n",
    "        assert not self.layers, \"Weights can only be loaded once!\"\n",
    "        #add the saved matrix values to the convolutional network\n",
    "        for k in range(len(weights.keys())):\n",
    "            self.layers.append(weights['layer_{}'.format(k)])\n",
    "            \n",
    "    def predict(self,X):\n",
    "        h = self.cnn_layer(X, layer_i=0,border_mode=\"full\");X=h #*difference\n",
    "        h = self.relu_layer(X);X=h;\n",
    "        h = self.cnn_layer(X, layer_i=2,bordor_mode=\"full\");X=h  #*difference\n",
    "        h = self.relu_layer(X);X=h;\n",
    "        h = self.maxpooling_layer(X);X=h;\n",
    "        h = self.dropout_layer(X, .25);X=h; #*difference\n",
    "        h = self.flatten_layer(X, layer_i=7);X=h;\n",
    "        h = self.dense_layer(X, fully, layer_i = 10);X=h; #*difference \n",
    "        h = self.softmax_layer2D(X);X=h;\n",
    "        \n",
    "        #choose max \n",
    "        max_i = self.classify(X)\n",
    "        return max_i[0] #return max_i[o]\n",
    "    \n",
    "    \n",
    "    ''' Sub Process to Deep in Layer '''\n",
    "    \n",
    "    ''' Cnn Layer '''\n",
    "    def cnn_layer(self, X, layer_i=0, boder_mode=\"full\"):\n",
    "        features = self.layers[layer_i][\"param_0\"]\n",
    "        bias = self.layers[layer_i][\"param_1\"]\n",
    "        \n",
    "        #define filter maxtrick \n",
    "        path_dim = features[0].shape[-1]\n",
    "        #how many features do we have?\n",
    "        nb_features = features[0].shape[0]\n",
    "        #size image \n",
    "        image_dim = X.shape[2]\n",
    "        #RGB values \n",
    "        image_channals = X.shape[1]\n",
    "        #how many images do we have ?\n",
    "        nb_images = X.shape[0]\n",
    "        \n",
    "        #border mode is help to get output full image to filter or small image than to filter \n",
    "        if boder_mode == \"full\":\n",
    "            conv_dim = image_dim + path_dim-1\n",
    "        elif boder_mode == \"valid\":\n",
    "            conv_dim = image_dim - path_dim+1\n",
    "        \n",
    "        #initalize our feature matrix \n",
    "        convolved_features = np.zeros((nb_images, nb_features, conv_dim,conv_dim))  #2 conv_dim because have 2 cnn_layer\n",
    "        \n",
    "        #iterate through each image that we have\n",
    "        for image_i in range(nb_images):\n",
    "             #for each featues \n",
    "            for feature_i in range(features):\n",
    "                #init a convolved images as empty \n",
    "                convolved_image = np.zeros((conv_dim, conv_dim))\n",
    "                #then for each channell(rgb)\n",
    "                for channel in range(image_channals):\n",
    "                    #let extract a channel from our feature map \n",
    "                    feature = features[feature_i, channel,:,:]\n",
    "                    #the define a channel specific part of out image \n",
    "                    image = X[image_i, channel, :,:]\n",
    "                    #perform convolution on our image, using a given feature fillter \n",
    "                    convolved_image += self.convolved2d(image, feature, border_mode);\n",
    "                #add bias to our convoved image \n",
    "                convolved_image = convolved_image+bias[feature_i]\n",
    "                #add it to our list of convolved features (learnings)\n",
    "                convolved_features[image_i, feature_i,:,:] = convolved_image \n",
    "        return convolved_features\n",
    "    \n",
    "    ''' Reru Layer'''\n",
    "    def relu_layer(x):\n",
    "        #turn all negative values in a matrix into zeros\n",
    "        z = np.zeros_like(x)\n",
    "        return np.where(x>z,x,z)\n",
    "    \n",
    "    ''' Pooling Layer ''' \n",
    "    def maxpooling_layer(self, convolved_features):\n",
    "        #given our learned features and images\n",
    "        nb_features = convolved_features.shape[0]\n",
    "        nb_images = convolved_features.shape[1]\n",
    "        conv_dim = convolved_features.shape[2] #full or vaild \n",
    "        res_dim = int(conv_dim / self.pool_size)       #assumed square shape\n",
    "        \n",
    "        #initialize our more dense feature list as empty\n",
    "        pooled_features = np.zeros((nb_features, nb_images, res_dim, res_dim)) #same feature maxtrix\n",
    "        \n",
    "        #for each image\n",
    "        for image_i in range(nb_images):\n",
    "            #and each feature map\n",
    "            for feature_i in range(nb_features):\n",
    "                #begin by the row\n",
    "                for pool_row in range(res_dim):\n",
    "                    #define start and end points\n",
    "                    row_start = pool_row * self.pool_size\n",
    "                    row_end   = row_start + self.pool_size\n",
    "                    #for each column (so its a 2D iteration)\n",
    "                    for pool_col in range(res_dim):\n",
    "                        #define start and end points\n",
    "                        col_start = pool_col * self.pool_size\n",
    "                        col_end   = col_start + self.pool_size\n",
    "                        #define a patch given our defined starting ending points\n",
    "                        patch = convolved_features[feature_i, image_i, row_start : row_end,col_start : col_end]\n",
    "                        #then take the max value from that patch\n",
    "                        #store it. this is our new learned feature/filter\n",
    "                        pooled_features[feature_i, image_i, pool_row, pool_col] = np.max(patch)\n",
    "                        return pooled_features\n",
    "                    \n",
    "    ''' Dropout Layer'''\n",
    "    def dropout_layer(X, p):  #i aussume 0.25 to p \n",
    "        retain_prob = 1. - p\n",
    "        X *= retain_prob\n",
    "        return X\n",
    "    ''' Flatten Layer '''\n",
    "        #tensor transformation, less dimensions\n",
    "        #tranlate -> แปลงมิติ เมททริกซ์ ให้มีขนาดน้อยลง\n",
    "    def flatten_layer(X):\n",
    "        flatX = np.zeros((X.shape[0],np.prod(X.shape[1:])))\n",
    "        for i in range(X.shape[0]):\n",
    "            flatX[i,:] = X[i].flatten(order='C')\n",
    "        return flatX\n",
    "    \n",
    "    ''' Dense Layer '''\n",
    "    #In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
    "        #tranlate -> ในชั้นหนาแน่นทุกโหนดในชั้นเชื่อมต่อกับทุกโหนดในชั้นก่อนหน้า\n",
    "    def dense_layer(self, X, layer_i=0):\n",
    "        #so we'll initialize our weight and bias for this layer\n",
    "        W = self.layers[layer_i][\"param_0\"]\n",
    "        b = self.layers[layer_i][\"param_1\"]\n",
    "        #and multiply it by our input (dot product)\n",
    "        output = np.dot(X, W) + b\n",
    "        return output\n",
    "    \n",
    "    ''' Soft max 2D'''\n",
    "    def softmax_layer2D(w):\n",
    "        #this function will calculate the probabilities of each\n",
    "        #target class over all possible target classes. \n",
    "        maxes = np.amax(w, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        e = np.exp(w - maxes)\n",
    "        dist = e / np.sum(e, axis=1, keepdims=True)\n",
    "        return dist\n",
    "    \n",
    "    ''' Classifier'''\n",
    "        #get the largest probabililty value from the list\n",
    "    def classify(X):\n",
    "        return X.argmax(axis=-1)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    #so what does the convolution operation look like?, given an image and a feature map (filter)\n",
    "    def convolve2d(image, feature, border_mode=\"full\"):\n",
    "        #we'll define the tensor dimensions of the image and the feature\n",
    "        image_dim = np.array(image.shape)\n",
    "        feature_dim = np.array(feature.shape)\n",
    "        #as well as a target dimension\n",
    "        target_dim = image_dim + feature_dim - 1\n",
    "        \n",
    "        #then we'll perform a fast fourier transform on both the input and the filter\n",
    "        #performing a convolution can be written as a for loop but for many convolutions\n",
    "        #this approach is too comp. expensive/slow. it can be performed orders of magnitude\n",
    "        #faster using a fast fourier transform. \n",
    "        fft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim)\n",
    "        #and set the result to our target \n",
    "        target = np.fft.ifft2(fft_result).real\n",
    "        \n",
    "        if border_mode == \"valid\":\n",
    "            # To compute a valid shape, either np.all(x_shape >= y_shape) or\n",
    "            # np.all(y_shape >= x_shape).\n",
    "            #decide a target dimension to convolve around\n",
    "            valid_dim = image_dim - feature_dim + 1\n",
    "            if np.any(valid_dim < 1):\n",
    "                valid_dim = feature_dim - image_dim + 1\n",
    "                start_i = (target_dim - valid_dim) // 2\n",
    "                end_i = start_i + valid_dim\n",
    "                target = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n",
    "                return target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    self.vocab = meta[\"vocab\"]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "'''OCR Path'''\n",
    "import pickle #saving and loading our serialized model \n",
    "import numpy as np #matrix math\n",
    "from app.model.preprocessor import Preprocessor as img_prep #image preprocessing\n",
    "\n",
    "#class for loading our saved model and classifying new images\n",
    "class LiteOCR:\n",
    "    def __init__(self, fn=\"alpha_weights.pkl\", pool_size=2):\n",
    "        #load the weights from the pickle file and the meta data\n",
    "        [weights, meta] = pickle.load(open(fn, 'rb'), encoding='latin1') #currently, this class MUST be initialized from a pickle file\n",
    "        #list to store labels\n",
    "        self.vocab = meta[\"vocab\"]\n",
    "        \n",
    "#how many rows and columns in an image\n",
    "\t\tself.img_rows = meta[\"img_side\"] ; self.img_cols = meta[\"img_side\"]\n",
    "        \n",
    "        #load our CNN\n",
    "\t\tself.CNN = LiteCNN()\n",
    "        #with our saved weights\n",
    "\t\tself.CNN.load_weights(weights)\n",
    "        #define the pooling layers size\n",
    "\t\tself.CNN.pool_size=int(pool_size)\n",
    "    \n",
    "    #classify new image\n",
    "\tdef predict(self, image):\n",
    "\t\tprint(image.shape)\n",
    "        #vectorize the image into the right shape for our network\n",
    "\t\tX = np.reshape(image, (1, 1, self.img_rows, self.img_cols))\n",
    "\t\tX = X.astype(\"float32\")\n",
    "        \n",
    "        #make the prediction\n",
    "\t\tpredicted_i = self.CNN.predict(X)\n",
    "        #return the predicted label\n",
    "\t\treturn self.vocab[predicted_i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
